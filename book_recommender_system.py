# -*- coding: utf-8 -*-
"""book-recommender-system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d-Y1yW9BMqcYPSr8esC2-WaTr_K-AghW

#**Proyek Sistem Rekomendasi: Books**


Buku telah menjadi salah satu sumber informasi dan hiburan paling penting bagi manusia selama berabad-abad. Namun, dengan semakin banyaknya judul buku yang diterbitkan setiap tahun, pembaca sering kali kesulitan menemukan buku yang sesuai dengan minat mereka. Menurut data dari International Publishers Association, lebih dari 2 juta judul buku baru diterbitkan secara global setiap tahunnya [1]. Hal ini menciptakan fenomena yang dikenal sebagai "paradox of choice" atau paradoks pilihan, di mana terlalu banyak opsi justru membuat konsumen kesulitan untuk membuat keputusan [2].

Sistem rekomendasi buku hadir sebagai solusi untuk masalah ini. Dengan memanfaatkan teknik machine learning, sistem rekomendasi dapat menganalisis data karakteristik buku dan preferensi pengguna untuk memberikan rekomendasi yang lebih personal dan relevan. Penelitian oleh Adomavicius dan Tuzhilin menunjukkan bahwa sistem rekomendasi yang efektif dapat meningkatkan kepuasan pengguna hingga 27% dan meningkatkan peluang transaksi hingga 35% [3].

Dalam proyek ini, saya mengembangkan sistem rekomendasi buku menggunakan dataset Kaggle yang berisi informasi detail tentang ribuan buku. Dengan memadukan pendekatan content-based filtering dan collaborative filtering, proyek ini bertujuan untuk memberikan rekomendasi buku yang akurat dan personal kepada pengguna berdasarkan kesamaan konten buku dan pola peringkat dari pengguna lain.

## **Import Library**

Di tahap awal ini, seluruh library yang diperlukan untuk proses analisis dan pengembangan sistem rekomendasi berbasis dataset buku diimpor terlebih dahulu. Langkah ini penting untuk memastikan semua fungsi yang dibutuhkan  mulai dari praproses data, analisis, visualisasi, hingga pembuatan model rekomendasi sudah siap digunakan sejak awal.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_squared_error
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import nltk
from nltk.corpus import stopwords
import warnings
warnings.filterwarnings("ignore")

"""## Load Dataset

Membaca file CSV dan Menampilkan data 5 teratas dan terbawah
"""

df = pd.read_csv('/content/Books.csv')

df.head() # menampilkan 5 data teratas

"""## **Data Understanding**

Pada tahap ini dilakukan proses pemahaman awal terhadap dataset yang akan digunakan dalam sistem rekomendasi buku. Tujuannya adalah untuk mengetahui struktur data, jenis informasi yang tersedia, serta mengecek adanya data yang hilang (missing values). Proses ini penting agar kita bisa menentukan langkah pembersihan dan transformasi data yang sesuai sebelum membangun model.
"""

# Tampilkan informasi data yang bernilai null
print("Missing Values:\n", df.isnull().sum())

"""**Insight:**

Beberapa kolom masih memiliki data yang kosong, terutama pada bagian subtitle, authors, dan description. Namun, kolom-kolom utama seperti isbn, title, dan userId sudah lengkap, jadi dataset masih cukup layak untuk digunakan setelah menangani missing values yang ada.

## **EDA**

Langkah ini bertujuan untuk memahami struktur data, ringkasan statistik, distribusi nilai, serta deteksi awal terhadap duplikasi dan nilai kosong. Ini penting untuk memastikan kualitas data sebelum modeling. EDA sangat penting dalam sistem rekomendasi karena dapat mengungkapkan insight penting yang dapat memengaruhi pemodelan, seperti distribusi rating, popularitas penulis, dan kelengkapan informasi buku.
"""

df.info() # Menampilkan informasi data

"""**Insight:**

Dataset berisi 6.810 entri dengan 13 kolom. Sebagian besar kolom terisi cukup lengkap, meskipun ada beberapa kolom seperti subtitle, authors, dan description yang masih memiliki data kosong. Tipe data juga sudah sesuai untuk analisis lanjutan, jadi secara umum dataset ini siap digunakan setelah sedikit pembersihan.
"""

df.describe() # Memberikan statistik deskriptif

"""**Insight**

Dataset ini terdiri dari 6.810 buku, yang memberikan gambaran yang cukup luas untuk analisis rekomendasi. Sebagian besar buku dalam dataset diterbitkan pada tahun 2000-an, dengan rata-rata tahun terbit 1998. Rating buku cenderung seragam, dengan rata-rata 3.93 dan sedikit variasi. Meskipun demikian, terdapat buku dengan rating 0, yang mungkin menunjukkan data yang tidak lengkap atau belum diberi rating oleh pengguna. Untuk jumlah halaman, rata-rata buku memiliki sekitar 348 halaman, meskipun ada beberapa entri yang mencatatkan jumlah halaman 0, yang seharusnya ditinjau lebih lanjut. Dari sisi jumlah rating, sebagian besar buku memiliki sedikit rating, sementara beberapa lainnya menerima rating yang sangat banyak, menunjukkan ketidakmerataan dalam interaksi pengguna dengan buku-buku tersebut.
"""

# Menyajikan jumlah total data, jumlah nilai valid (Non-NaN), dan nilai kosong (NaN) untuk setiap kolom dalam bentuk tabel.
print(pd.DataFrame({'Total Data': df.shape[0], 'Non-NaN': df.count(), 'NaN': df.isna().sum()}))

"""**Insight:**

Berdasarkan pengecekan data, sebagian besar kolom dalam dataset tidak memiliki nilai kosong (NaN). Kolom seperti isbn13, isbn10, title, dan userId sudah lengkap tanpa data yang hilang. Namun, ada beberapa kolom yang memiliki jumlah nilai kosong, seperti subtitle dengan 4.429 nilai kosong, serta authors, categories, thumbnail, dan description, yang masing-masing memiliki nilai kosong di bawah 100. Kolom published_year, average_rating, num_pages, dan ratings_count juga memiliki sedikit data yang hilang, masing-masing sekitar 40 entri.
"""

# Fungsi bantu plotting
def plot_hist(data, title, xlabel, bins=30, log=False):
    plt.figure(figsize=(10,5))
    sns.histplot(data.dropna(), bins=bins, log_scale=log)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.show()

def plot_box(data, title):
    plt.figure(figsize=(10,2))
    sns.boxplot(x=data.dropna())
    plt.title(title)
    plt.show()

# --- Title / Subtitle ---
df['title_length'] = df['title'].astype(str).apply(len)
plot_hist(df['title_length'], "Panjang Judul Buku", "Jumlah Karakter")

if df['subtitle'].notnull().sum() > 0:
    df['subtitle_length'] = df['subtitle'].astype(str).apply(len)
    plot_hist(df['subtitle_length'], "Panjang Subjudul Buku", "Jumlah Karakter")

"""**Insight:**

Berdasarkan visualisasi distribusi panjang karakter pada kolom title dan subtitle, dapat dilihat bahwa sebagian besar buku memiliki judul yang pendek, dengan jumlah karakter kurang dari 50. Hanya sebagian kecil buku yang memiliki judul yang lebih panjang. Begitu juga dengan kolom subtitle, di mana sebagian besar subjudul buku memiliki panjang yang sangat pendek, dengan banyak nilai yang mendekati 0. Hal ini menunjukkan bahwa banyak buku yang tidak memiliki subjudul, atau jika ada, subjudulnya cukup singkat. Visualisasi ini memberikan gambaran mengenai distribusi panjang teks dalam dataset, yang bisa digunakan untuk analisis lebih lanjut atau penyesuaian model yang lebih sesuai dengan panjang teks.








"""

# --- Authors ---
top_authors = df['authors'].value_counts().head(10)
top_authors.plot(kind='bar', title='Top 10 Penulis Produktif')
plt.ylabel('Jumlah Buku')
plt.xticks(rotation=45)
plt.show()

"""**Insight:**

Berdasarkan visualisasi ini, Agatha Christie dan Stephen King muncul sebagai penulis paling produktif dalam dataset ini, dengan masing-masing memiliki lebih dari 35 buku yang tercatat. Diikuti oleh penulis terkenal lainnya seperti William Shakespeare, John Ronald Reuel Tolkien, dan Virginia Woolf yang juga memiliki jumlah buku yang signifikan. Meskipun demikian, penulis-penulis seperti Piers Anthony dan Terry Brooks berada di urutan bawah dengan jumlah buku yang lebih sedikit. Grafik ini memberikan wawasan tentang penulis yang lebih dominan dalam dataset dan dapat membantu dalam menganalisis tren atau preferensi buku berdasarkan penulis.
"""

# --- Categories ---
top_categories = df['categories'].value_counts().head(10)
top_categories.plot(kind='bar', title='Top 10 Kategori Buku')
plt.ylabel('Jumlah Buku')
plt.xticks(rotation=45)
plt.show()

"""**Insight:**

Berdasarkan grafik ini, kategori Fiction mendominasi dataset dengan lebih dari 2.500 buku, yang menunjukkan popularitas dan keberagaman dalam genre fiksi. Diikuti oleh kategori Juvenile Fiction yang memiliki jumlah buku yang signifikan, namun jauh lebih rendah dibandingkan fiksi umum. Kategori lain seperti Biography & Autobiography, Literary Criticism, dan Comics & Graphic Novels juga tercatat, namun dengan jumlah buku yang jauh lebih sedikit. Hal ini memberikan gambaran tentang preferensi genre buku yang lebih umum di dataset ini, dengan fiksi menjadi kategori yang paling populer.
"""

# --- Description length ---
df['desc_length'] = df['description'].astype(str).apply(len)
plot_hist(df['desc_length'], "Panjang Deskripsi Buku", "Jumlah Karakter")

"""**Insight:**

Berdasarkan visualisasi ini, deskripsi buku sebagian besar memiliki panjang yang sangat singkat, dengan banyak buku memiliki deskripsi kurang dari 1.000 karakter. Beberapa buku memiliki deskripsi yang jauh lebih panjang, namun jumlahnya relatif sedikit. Hal ini menunjukkan bahwa sebagian besar buku mungkin memiliki deskripsi yang ringkas atau bahkan tidak lengkap.
"""

# --- Published Year ---
plot_hist(df['published_year'], "Distribusi Tahun Terbit", "Tahun")
plot_box(df['published_year'], "Boxplot Tahun Terbit")

"""**Insight:**

Untuk distribusi tahun terbit, grafik menunjukkan bahwa sebagian besar buku diterbitkan setelah tahun 2000, dengan lonjakan tajam pada periode tersebut. Sebelumnya, buku-buku lebih jarang diterbitkan, terutama sebelum tahun 1970-an, dan ada beberapa nilai pencilan (outliers) yang muncul dalam boxplot yang menunjukkan buku-buku yang diterbitkan lebih awal atau terlambat dari rentang umum. Ini memberikan wawasan bahwa dataset ini didominasi oleh buku-buku modern yang lebih baru.
"""

# --- Average Rating ---
plot_hist(df['average_rating'], "Distribusi Rating Rata-rata", "Rating", bins=20)
plot_box(df['average_rating'], "Boxplot Rating")

"""**Insight:**

Berdasarkan grafik distribusi rating rata-rata, sebagian besar buku dalam dataset memiliki rating antara 3 hingga 5, dengan puncaknya pada rating 4. Ini menunjukkan bahwa banyak buku yang mendapat penilaian yang cukup positif dari pembaca. Boxplot juga mengonfirmasi hal ini, dengan median yang dekat dengan 4 dan beberapa outlier di bawah nilai tersebut. Data ini memberikan gambaran bahwa meskipun sebagian besar buku dinilai dengan baik, ada beberapa buku yang mendapat penilaian sangat rendah.
"""

# --- Num Pages ---
plot_hist(df['num_pages'], "Distribusi Jumlah Halaman", "Halaman", bins=40)
plot_box(df['num_pages'], "Boxplot Halaman")

"""**Insight:**

Berdasarkan grafik distribusi jumlah halaman, mayoritas buku dalam dataset memiliki jumlah halaman antara 0 hingga 500, dengan puncaknya pada rentang 200-400 halaman. Ada beberapa buku dengan jumlah halaman yang lebih sedikit, sementara buku dengan jumlah halaman sangat tinggi (lebih dari 2000) sangat jarang. Boxplot juga menunjukkan adanya banyak outliers, yaitu buku dengan jumlah halaman yang jauh lebih banyak dari rata-rata, yang bisa menunjukkan buku-buku dengan jumlah halaman ekstrim atau bahkan kesalahan dalam data. Hal ini memberi gambaran bahwa sebagian besar buku cukup pendek, namun ada juga beberapa buku yang lebih panjang dari biasanya.
"""

# --- Ratings Count ---
plot_hist(df['ratings_count'], "Distribusi Jumlah Review", "Jumlah Review", bins=50, log=True)
plot_box(df['ratings_count'], "Boxplot Jumlah Review")

"""**Insight:**

Berdasarkan grafik distribusi jumlah review, sebagian besar buku memiliki jumlah review yang relatif rendah, namun ada beberapa buku yang mendapatkan jumlah review yang sangat tinggi, terlihat pada sisi kanan grafik. Hal ini menunjukkan bahwa beberapa buku sangat populer dan sering diulas oleh pembaca. Boxplot juga mengonfirmasi adanya banyak outliers pada jumlah review, yang berarti ada buku-buku dengan jumlah review yang jauh lebih tinggi dibandingkan buku lainnya. Distribusi ini mengindikasikan ketidakmerataan dalam interaksi pengguna dengan buku, di mana sebagian besar buku mendapatkan sedikit perhatian, sementara beberapa buku menerima perhatian yang sangat besar.








"""

# --- Missing data visualisasi ---
plt.figure(figsize=(10,5))
df.isnull().mean().sort_values(ascending=False).plot(kind='bar')
plt.title("Persentase Missing Data per Kolom")
plt.ylabel("Proporsi Null")
plt.show()

"""**Insight:**

Berdasarkan visualisasi persentase data yang hilang, kolom subtitle memiliki proporsi data yang hilang paling tinggi, mencapai lebih dari 60%, yang menunjukkan bahwa banyak buku tidak memiliki subjudul. Selain itu, kolom thumbnail dan description juga memiliki persentase data hilang yang signifikan, meskipun jauh lebih rendah dibandingkan subtitle. Kolom lainnya, seperti authors, ratings_count, num_pages, dan average_rating, memiliki persentase data hilang yang relatif kecil. Ini menunjukkan bahwa sebagian besar informasi penting dalam dataset tersedia, namun ada beberapa kolom yang memerlukan perhatian lebih dalam hal pengolahan data hilang.

## **Data Preparation**

Tahap ini berfokus pada pembuatan fitur utama yang akan digunakan dalam sistem rekomendasi berbasis Content-Based Filtering. Pendekatan ini merekomendasikan buku dengan cara membandingkan kesamaan kontennya — dalam hal ini berdasarkan teks seperti judul, penulis, kategori, dan deskripsi buku.

#### Handle Missing Values dan Normalisasi
"""

# a. Handle missing values
for col in ['subtitle', 'authors', 'categories', 'description']:
    df[col] = df[col].fillna('')

# b. Text normalization (simple lowercase)
for col in ['title', 'subtitle', 'authors', 'categories', 'description']:
    df[col] = df[col].str.lower()

"""**Insight:**

langkah ini bertujuan untuk membersihkan data dan meningkatkan konsistensi. Pertama, nilai yang hilang di kolom subtitle, authors, categories, dan description diisi dengan string kosong untuk menghindari masalah data yang hilang. Kemudian, teks dalam kolom title, subtitle, authors, categories, dan description diubah menjadi huruf kecil agar lebih seragam, sehingga memudahkan pemrosesan lebih lanjut tanpa terpengaruh perbedaan kapitalisasi.

#### Gabungkan Fitur Teks
"""

# c. Gabungkan fitur teks
df['features'] = (
    df['title'] + ' ' +
    df['subtitle'] + ' ' +
    df['authors'] + ' ' +
    df['categories'] + ' ' +
    df['description']
)

"""**Insight:**

Pada langkah ini, fitur teks dari kolom title, subtitle, authors, categories, dan description digabungkan menjadi satu kolom baru bernama features. Hal ini bertujuan untuk menciptakan representasi teks yang lebih lengkap dan komprehensif untuk setiap buku, yang akan digunakan dalam proses analisis lebih lanjut, seperti perhitungan kemiripan antar buku.

#### TF-IDF Vectorization dan Similarity
"""

# d. Vectorize
vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
tfidf_matrix = vectorizer.fit_transform(df['features'])

# e. Compute similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""**Insight:**

Pada langkah ini, teks yang telah digabungkan dalam kolom features diubah menjadi representasi numerik menggunakan TF-IDF Vectorizer. Dengan mengabaikan kata-kata umum (stop words) dalam bahasa Inggris dan membatasi jumlah fitur menjadi 5.000, model ini menghasilkan matriks TF-IDF yang menggambarkan pentingnya setiap kata dalam konteks buku. Selanjutnya, Cosine Similarity dihitung untuk mengukur kemiripan antar buku berdasarkan fitur teks tersebut, sehingga memungkinkan sistem untuk memberikan rekomendasi buku yang serupa.

#### Lookup Dictionary
"""

# f. Build lookup
title_to_idx = pd.Series(df.index, index=df['title']).drop_duplicates()

"""**Insight:**

Pada langkah ini, sebuah lookup dictionary dibuat dengan menghubungkan setiap judul buku (title) ke indeksnya dalam dataset. Dengan menggunakan pd.Series(), kolom title digunakan sebagai index dan indeks buku yang sesuai menjadi nilai. Ini memungkinkan pencarian cepat berdasarkan judul buku, yang berguna ketika memberikan rekomendasi atau mencari informasi terkait buku tertentu dalam sistem.

#### Pivot Table dan Train-Test Split
"""

# g. Buat pivot table (user-item)
pivot = df.pivot_table(
    index="userId",
    columns="isbn13",
    values="average_rating",
    fill_value=0
)

# e. Split data: sebagian user untuk test set
trainset, testset = train_test_split(
    pivot,
    test_size=0.2,
    random_state=42
)

"""**Insight:**

Pada langkah ini, pertama dibuat pivot table yang menghubungkan pengguna (userId) dengan buku berdasarkan isbn13, dan menggunakan average_rating sebagai nilai. Ini menghasilkan tabel yang memetakan pengguna ke buku-buku yang telah mereka beri rating, dengan nilai 0 untuk buku yang belum diberi rating.

Selanjutnya, data dibagi menjadi trainset dan testset menggunakan train_test_split, dengan 20% data digunakan sebagai test set untuk validasi model. Pembagian ini memungkinkan model untuk dilatih pada data pengguna yang ada, sekaligus diuji pada data yang belum terlihat untuk mengukur kinerjanya.

## **Model Development dengan Content-Based Filtering**

Pada tahap ini dikembangkan sebuah model rekomendasi berbasis Content-Based Filtering, yaitu sistem yang merekomendasikan buku-buku yang memiliki konten serupa dengan buku yang dipilih pengguna. Model ini bekerja dengan membandingkan representasi teks (judul, deskripsi, kategori, penulis) menggunakan cosine similarity.
"""

def recommend_content(title, top_n=5):
    title = title.lower()
    if title not in title_to_idx:
        raise ValueError(f"'{{title}}' not ditemukan di dataset")
    idx = title_to_idx[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n+1]
    book_indices = [i[0] for i in sim_scores]
    return df[['title', 'authors', 'average_rating']].iloc[book_indices]

# Demo content-based
try:
    sample = df['title'].iloc[0]
    print("Contoh rekomendasi (Content-Based) untuk:", sample)
    print(recommend_content(sample, top_n=5))
except Exception as e:
    print(e)

"""**Insight:**

Pada tahap ini memberikan rekomendasi buku berdasarkan kesamaan konten. Setelah memeriksa apakah judul buku ada dalam dataset, fungsi ini menghitung Cosine Similarity untuk menentukan buku mana yang paling mirip. Kemudian, ia mengurutkan buku-buku berdasarkan skor kemiripan dan menampilkan 5 rekomendasi teratas. Misalnya, jika mencari buku "gilead", sistem akan merekomendasikan buku seperti Go Tell It On the Mountain oleh James Baldwin dengan rating 4.01, yang menunjukkan bahwa sistem efektif dalam memberikan saran yang relevan berdasarkan buku yang telah dibaca.

## **Model Development dengan Collaborative Filtering**

Tahap ini membangun sistem rekomendasi buku berdasarkan preferensi pengguna lain menggunakan pendekatan Collaborative Filtering. Berbeda dengan Content-Based yang fokus pada fitur buku, Collaborative Filtering memanfaatkan pola rating dari banyak pengguna untuk memperkirakan minat pengguna tertentu terhadap buku yang belum mereka baca.

#### Latent Factor Model: Truncated SVD
"""

# 1. Latent factor model (Truncated SVD)
svd = TruncatedSVD(n_components=20, random_state=42)
svd.fit(trainset)

"""#### Hitung RMSE dari Rekonstruksi Test Set"""

# 2. Hitung RMSE
latent_test    = svd.transform(testset)
testset_approx = np.dot(latent_test, svd.components_)

rmse = np.sqrt(mean_squared_error(
    testset.values.flatten(),
    testset_approx.flatten()
))
print(f"▶ RMSE (TruncatedSVD) : {rmse:.4f}\n")

"""#### Fungsi Rekomendasi Buku per User"""

# 3. Fungsi rekomendasi yang mengembalikan DataFrame
def recommend_books_user(user_id, n=5):
    if user_id not in pivot.index:
        raise ValueError(f"User ID {user_id} tidak ditemukan di dataset.")

    # Representasi laten user
    latent_user = svd.transform(pivot.loc[[user_id]])
    pred_ratings = np.dot(latent_user, svd.components_).flatten()

    # Series prediksi rating
    pred_series = pd.Series(pred_ratings, index=pivot.columns)

    # Filter item belum di-rating (rating = 0)
    unrated = pred_series[pivot.loc[user_id] == 0]

    # Ambil top-n berdasarkan prediksi
    top_n = unrated.nlargest(n)

    # Bangun DataFrame rekomendasi
    rec_df = top_n.reset_index()
    rec_df.columns = ['isbn13', 'PredictedRating']

    # Map isbn ke judul buku
    title_map = df.set_index('isbn13')['title'].to_dict()
    rec_df['Title'] = rec_df['isbn13'].map(title_map).fillna(rec_df['isbn13'])

    # Atur ulang kolom
    rec_df = rec_df[['Title', 'PredictedRating']]
    rec_df['PredictedRating'] = rec_df['PredictedRating'].round(2)

    return rec_df

"""**Insight:**

Fungsi recommend_books_user() memberikan rekomendasi buku untuk pengguna berdasarkan prediksi rating yang dihasilkan oleh model. Pertama, fungsi ini menghitung representasi laten pengguna dari data yang tersedia, kemudian memprediksi rating untuk buku yang belum diberikan rating oleh pengguna tersebut. Buku yang belum di-rating (rating = 0) dipilih untuk diprediksi dan diurutkan berdasarkan rating tertinggi. Setelah itu, fungsi membangun DataFrame dengan ISBN dan rating yang diprediksi, serta menghubungkan ISBN dengan judul buku untuk mempermudah pemahaman. Hasil akhirnya adalah daftar rekomendasi buku yang dapat disarankan kepada pengguna berdasarkan preferensi mereka.

#### Contoh Pemanggilan Fungsi Rekomendasi
"""

# 4. Contoh pemanggilan
user_test = 1
try:
    print(f"▶ Rekomendasi untuk userId {user_test}:\n")
    print(recommend_books_user(user_test, n=5).to_string(index=False))
except ValueError as e:
    print("⚠", e)

"""**Insight:**

Pada tahap ini, memberikan rekomendasi buku untuk pengguna berdasarkan ID pengguna yang diberikan. Misalnya, untuk userId 1, sistem merekomendasikan buku dengan judul seperti Fanning the Flame, The Diamond Color Meditation, dan The Feynman Lectures on Physics. Setiap buku dilengkapi dengan rating yang diprediksi, meskipun rating prediksi untuk buku-buku ini cenderung sangat rendah (sekitar 0.01 hingga 0.02). Hal ini menunjukkan bahwa meskipun sistem memberikan rekomendasi, kualitas atau relevansi rekomendasi masih bergantung pada data pelatihan dan model yang digunakan.

## **Evaluasi**

Pada tahap ini, kita mengukur performa kedua metode rekomendasi yang telah dikembangkan, yaitu Content-Based Filtering dan Collaborative Filtering, menggunakan metrik yang sesuai.
"""

print("\n▶ Evaluasi Content-Based Filtering")

# Precision@K (Proxy via Cosine Similarity)
def precision_at_k(sim_scores, k=5, threshold=0.5):
    top_k = np.sort(sim_scores)[-k:]  # ambil k skor tertinggi
    relevant = top_k[top_k >= threshold]
    precision = len(relevant) / k
    return precision

# Ambil cosine similarity untuk satu buku contoh
book_index = 0  # indeks buku yang akan dijadikan referensi
sim_scores = cosine_sim[book_index]

# Hitung Precision@5
precision = precision_at_k(sim_scores, k=5, threshold=0.5)
print(f"Precision@5 (Cosine Similarity ≥ 0.5): {precision:.2f}")

# Relevance Score (rerata similarity top-K)
top_k_idx = sim_scores.argsort()[-5:][::-1]  # indeks top-5
relevance_scores = sim_scores[top_k_idx]
avg_relevance = np.mean(relevance_scores)
print(f"Rata-rata Relevance Score Top-5 Rekomendasi: {avg_relevance:.2f}")

# -------------------------------------------
# 2. Evaluasi Collaborative Filtering
# -------------------------------------------

print("\n▶ Evaluasi Collaborative Filtering")

# Asumsikan `trainset`, `testset`, dan `svd` sudah tersedia dari langkah sebelumnya
latent_test = svd.transform(testset)
testset_approx = np.dot(latent_test, svd.components_)
rmse = np.sqrt(mean_squared_error(testset.values.flatten(), testset_approx.flatten()))
print(f"Root Mean Square Error (RMSE): {rmse:.4f}")

"""**Insight:**


Pada tahap evaluasi ini, dua metode rekomendasi, yaitu Content-Based Filtering dan Collaborative Filtering, diuji dengan menggunakan metrik yang sesuai.

Untuk Content-Based Filtering, metrik Precision@5 dihitung menggunakan Cosine Similarity untuk mengukur sejauh mana buku yang direkomendasikan relevan dengan preferensi pengguna. Hasilnya menunjukkan Precision@5 sebesar 0.20, dengan Relevance Score rata-rata untuk Top-5 rekomendasi sebesar 0.36, yang menunjukkan bahwa meskipun ada kemiripan, relevansi bisa ditingkatkan.

Sedangkan untuk Collaborative Filtering, digunakan Root Mean Square Error (RMSE) untuk mengukur kesalahan prediksi antara nilai yang diprediksi dengan nilai aktual. RMSE yang diperoleh adalah 0.0479, yang menunjukkan bahwa model ini memberikan prediksi yang cukup akurat dengan kesalahan yang relatif kecil.

Secara keseluruhan, kedua metode menunjukkan kinerja yang cukup baik, dengan Collaborative Filtering memiliki kesalahan prediksi yang lebih rendah dibandingkan Content-Based Filtering.
"""